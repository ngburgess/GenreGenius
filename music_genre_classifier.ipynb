{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3beb3cf9-8dea-46c9-8453-1c0d331aca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import yt_dlp\n",
    "import librosa\n",
    "from pydub import AudioSegment\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445bb3c6-880a-4828-83b8-3763418f7300",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88fd5522-a202-4279-bf0b-9fca80703b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_var</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues.00000.wav</td>\n",
       "      <td>0.350088</td>\n",
       "      <td>0.088757</td>\n",
       "      <td>0.130228</td>\n",
       "      <td>0.002827</td>\n",
       "      <td>1784.165850</td>\n",
       "      <td>129774.064525</td>\n",
       "      <td>2002.449060</td>\n",
       "      <td>85882.761315</td>\n",
       "      <td>3805.839606</td>\n",
       "      <td>...</td>\n",
       "      <td>52.420910</td>\n",
       "      <td>-1.690215</td>\n",
       "      <td>36.524071</td>\n",
       "      <td>-0.408979</td>\n",
       "      <td>41.597103</td>\n",
       "      <td>-2.303523</td>\n",
       "      <td>55.062923</td>\n",
       "      <td>1.221291</td>\n",
       "      <td>46.936035</td>\n",
       "      <td>Blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blues.00001.wav</td>\n",
       "      <td>0.340914</td>\n",
       "      <td>0.094980</td>\n",
       "      <td>0.095948</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>1530.176679</td>\n",
       "      <td>375850.073649</td>\n",
       "      <td>2039.036516</td>\n",
       "      <td>213843.755497</td>\n",
       "      <td>3550.522098</td>\n",
       "      <td>...</td>\n",
       "      <td>55.356403</td>\n",
       "      <td>-0.731125</td>\n",
       "      <td>60.314529</td>\n",
       "      <td>0.295073</td>\n",
       "      <td>48.120598</td>\n",
       "      <td>-0.283518</td>\n",
       "      <td>51.106190</td>\n",
       "      <td>0.531217</td>\n",
       "      <td>45.786282</td>\n",
       "      <td>Blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blues.00002.wav</td>\n",
       "      <td>0.363637</td>\n",
       "      <td>0.085275</td>\n",
       "      <td>0.175570</td>\n",
       "      <td>0.002746</td>\n",
       "      <td>1552.811865</td>\n",
       "      <td>156467.643368</td>\n",
       "      <td>1747.702312</td>\n",
       "      <td>76254.192257</td>\n",
       "      <td>3042.260232</td>\n",
       "      <td>...</td>\n",
       "      <td>40.598766</td>\n",
       "      <td>-7.729093</td>\n",
       "      <td>47.639427</td>\n",
       "      <td>-1.816407</td>\n",
       "      <td>52.382141</td>\n",
       "      <td>-3.439720</td>\n",
       "      <td>46.639660</td>\n",
       "      <td>-2.231258</td>\n",
       "      <td>30.573025</td>\n",
       "      <td>Blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blues.00003.wav</td>\n",
       "      <td>0.404785</td>\n",
       "      <td>0.093999</td>\n",
       "      <td>0.141093</td>\n",
       "      <td>0.006346</td>\n",
       "      <td>1070.106615</td>\n",
       "      <td>184355.942417</td>\n",
       "      <td>1596.412872</td>\n",
       "      <td>166441.494769</td>\n",
       "      <td>2184.745799</td>\n",
       "      <td>...</td>\n",
       "      <td>44.427753</td>\n",
       "      <td>-3.319597</td>\n",
       "      <td>50.206673</td>\n",
       "      <td>0.636965</td>\n",
       "      <td>37.319130</td>\n",
       "      <td>-0.619121</td>\n",
       "      <td>37.259739</td>\n",
       "      <td>-3.407448</td>\n",
       "      <td>31.949339</td>\n",
       "      <td>Blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blues.00004.wav</td>\n",
       "      <td>0.308526</td>\n",
       "      <td>0.087841</td>\n",
       "      <td>0.091529</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>1835.004266</td>\n",
       "      <td>343399.939274</td>\n",
       "      <td>1748.172116</td>\n",
       "      <td>88445.209036</td>\n",
       "      <td>3579.757627</td>\n",
       "      <td>...</td>\n",
       "      <td>86.099236</td>\n",
       "      <td>-5.454034</td>\n",
       "      <td>75.269707</td>\n",
       "      <td>-0.916874</td>\n",
       "      <td>53.613918</td>\n",
       "      <td>-4.404827</td>\n",
       "      <td>62.910812</td>\n",
       "      <td>-11.703234</td>\n",
       "      <td>55.195160</td>\n",
       "      <td>Blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename  chroma_stft_mean  chroma_stft_var  rms_mean   rms_var  \\\n",
       "0  blues.00000.wav          0.350088         0.088757  0.130228  0.002827   \n",
       "1  blues.00001.wav          0.340914         0.094980  0.095948  0.002373   \n",
       "2  blues.00002.wav          0.363637         0.085275  0.175570  0.002746   \n",
       "3  blues.00003.wav          0.404785         0.093999  0.141093  0.006346   \n",
       "4  blues.00004.wav          0.308526         0.087841  0.091529  0.002303   \n",
       "\n",
       "   spectral_centroid_mean  spectral_centroid_var  spectral_bandwidth_mean  \\\n",
       "0             1784.165850          129774.064525              2002.449060   \n",
       "1             1530.176679          375850.073649              2039.036516   \n",
       "2             1552.811865          156467.643368              1747.702312   \n",
       "3             1070.106615          184355.942417              1596.412872   \n",
       "4             1835.004266          343399.939274              1748.172116   \n",
       "\n",
       "   spectral_bandwidth_var  rolloff_mean  ...  mfcc16_var  mfcc17_mean  \\\n",
       "0            85882.761315   3805.839606  ...   52.420910    -1.690215   \n",
       "1           213843.755497   3550.522098  ...   55.356403    -0.731125   \n",
       "2            76254.192257   3042.260232  ...   40.598766    -7.729093   \n",
       "3           166441.494769   2184.745799  ...   44.427753    -3.319597   \n",
       "4            88445.209036   3579.757627  ...   86.099236    -5.454034   \n",
       "\n",
       "   mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  mfcc20_mean  \\\n",
       "0   36.524071    -0.408979   41.597103    -2.303523   55.062923     1.221291   \n",
       "1   60.314529     0.295073   48.120598    -0.283518   51.106190     0.531217   \n",
       "2   47.639427    -1.816407   52.382141    -3.439720   46.639660    -2.231258   \n",
       "3   50.206673     0.636965   37.319130    -0.619121   37.259739    -3.407448   \n",
       "4   75.269707    -0.916874   53.613918    -4.404827   62.910812   -11.703234   \n",
       "\n",
       "   mfcc20_var  label  \n",
       "0   46.936035  Blues  \n",
       "1   45.786282  Blues  \n",
       "2   30.573025  Blues  \n",
       "3   31.949339  Blues  \n",
       "4   55.195160  Blues  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/features_30_sec.csv\")\n",
    "df[\"label\"] = df[\"label\"].str.capitalize().replace(\"Hiphop\", \"Hip-hop\")\n",
    "df.drop(\"length\", axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b1a37d-b894-4f35-9b0d-7d1078d842c4",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7f2426e-3925-4399-9f98-58865244cea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.iloc[:, 1:58]\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(features)\n",
    "\n",
    "target = df[\"label\"]\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(target)\n",
    "\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ed87dd-c517-463a-85cb-ff856f1e6dbc",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10bfe5cd-c219-4cb2-953a-f60f364d3135",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad4272b3-7244-46ea-b7f8-a544e624b409",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, random_state=42, test_size=0.2)\n",
    "\n",
    "train_dataset = AudioDataset(X_train, y_train)\n",
    "test_dataset = AudioDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f722b900-a3a6-4fbf-b755-bb825973958b",
   "metadata": {},
   "source": [
    "## Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce292d4f-2840-4b21-b619-9aa0bb4941b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenreClassifier(nn.Module):\n",
    "    def __init__(self, input_features, output_features):\n",
    "        super(GenreClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_features, 48)\n",
    "        self.fc2 = nn.Linear(48, 24)\n",
    "        self.fc3 = nn.Linear(24, output_features)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "364ad4f0-7c1f-414c-9cd1-9bd5b7b7825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "num_features = features.shape[1]\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = GenreClassifier(num_features, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec216b59-9c33-4e62-b887-f02eac1b7721",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0993275-efa5-4552-902f-9b09b66234be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 2.2046\n",
      "Epoch: 2, Loss: 1.9416\n",
      "Epoch: 3, Loss: 1.6865\n",
      "Epoch: 4, Loss: 1.5237\n",
      "Epoch: 5, Loss: 1.3835\n",
      "Epoch: 6, Loss: 1.2603\n",
      "Epoch: 7, Loss: 1.1539\n",
      "Epoch: 8, Loss: 1.0659\n",
      "Epoch: 9, Loss: 0.9924\n",
      "Epoch: 10, Loss: 0.9256\n",
      "Epoch: 11, Loss: 0.8756\n",
      "Epoch: 12, Loss: 0.8272\n",
      "Epoch: 13, Loss: 0.7826\n",
      "Epoch: 14, Loss: 0.7447\n",
      "Epoch: 15, Loss: 0.7066\n",
      "Epoch: 16, Loss: 0.6724\n",
      "Epoch: 17, Loss: 0.6430\n",
      "Epoch: 18, Loss: 0.6140\n",
      "Epoch: 19, Loss: 0.5881\n",
      "Epoch: 20, Loss: 0.5672\n",
      "Epoch: 21, Loss: 0.5444\n",
      "Epoch: 22, Loss: 0.5220\n",
      "Epoch: 23, Loss: 0.5037\n",
      "Epoch: 24, Loss: 0.4788\n",
      "Epoch: 25, Loss: 0.4616\n",
      "Epoch: 26, Loss: 0.4419\n",
      "Epoch: 27, Loss: 0.4286\n",
      "Epoch: 28, Loss: 0.4135\n",
      "Epoch: 29, Loss: 0.3949\n",
      "Epoch: 30, Loss: 0.3801\n",
      "Epoch: 31, Loss: 0.3644\n",
      "Epoch: 32, Loss: 0.3495\n",
      "Epoch: 33, Loss: 0.3351\n",
      "Epoch: 34, Loss: 0.3273\n",
      "Epoch: 35, Loss: 0.3138\n",
      "Epoch: 36, Loss: 0.3021\n",
      "Epoch: 37, Loss: 0.2907\n",
      "Epoch: 38, Loss: 0.2787\n",
      "Epoch: 39, Loss: 0.2710\n",
      "Epoch: 40, Loss: 0.2606\n",
      "Epoch: 41, Loss: 0.2530\n",
      "Epoch: 42, Loss: 0.2451\n",
      "Epoch: 43, Loss: 0.2349\n",
      "Epoch: 44, Loss: 0.2230\n",
      "Epoch: 45, Loss: 0.2182\n",
      "Epoch: 46, Loss: 0.2087\n",
      "Epoch: 47, Loss: 0.2026\n",
      "Epoch: 48, Loss: 0.1926\n",
      "Epoch: 49, Loss: 0.1885\n",
      "Epoch: 50, Loss: 0.1823\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch: {epoch+1}, Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebf77f1-6ff9-4e9c-bbb6-bdf764869621",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e411ca1-1d39-42ae-ba91-c84930cb4c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7150\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, pred = torch.max(outputs, 1)\n",
    "\n",
    "        y_pred.extend(pred.cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "test_accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d80b19d6-20c0-4c6f-a3d5-97009a910182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chroma_stft_mean 0.0\n",
      "chroma_stft_var 0.020000000000000018\n",
      "rms_mean 0.020000000000000018\n",
      "rms_var 0.025000000000000022\n",
      "spectral_centroid_mean 0.025000000000000022\n",
      "spectral_centroid_var 0.020000000000000018\n",
      "spectral_bandwidth_mean 0.0050000000000000044\n",
      "spectral_bandwidth_var 0.015000000000000013\n",
      "rolloff_mean 0.015000000000000013\n",
      "rolloff_var 0.015000000000000013\n",
      "zero_crossing_rate_mean 0.020000000000000018\n",
      "zero_crossing_rate_var 0.010000000000000009\n",
      "harmony_mean 0.010000000000000009\n",
      "harmony_var 0.015000000000000013\n",
      "perceptr_mean 0.0050000000000000044\n",
      "perceptr_var 0.020000000000000018\n",
      "tempo -0.015000000000000013\n",
      "mfcc1_mean 0.03499999999999992\n",
      "mfcc1_var 0.010000000000000009\n",
      "mfcc2_mean 0.010000000000000009\n",
      "mfcc2_var 0.025000000000000022\n",
      "mfcc3_mean 0.020000000000000018\n",
      "mfcc3_var 0.0\n",
      "mfcc4_mean 0.06999999999999995\n",
      "mfcc4_var 0.020000000000000018\n",
      "mfcc5_mean 0.029999999999999916\n",
      "mfcc5_var 0.020000000000000018\n",
      "mfcc6_mean 0.03499999999999992\n",
      "mfcc6_var 0.025000000000000022\n",
      "mfcc7_mean 0.020000000000000018\n",
      "mfcc7_var 0.015000000000000013\n",
      "mfcc8_mean 0.015000000000000013\n",
      "mfcc8_var 0.0050000000000000044\n",
      "mfcc9_mean 0.025000000000000022\n",
      "mfcc9_var 0.025000000000000022\n",
      "mfcc10_mean 0.015000000000000013\n",
      "mfcc10_var 0.03499999999999992\n",
      "mfcc11_mean 0.0\n",
      "mfcc11_var 0.0\n",
      "mfcc12_mean 0.010000000000000009\n",
      "mfcc12_var 0.020000000000000018\n",
      "mfcc13_mean 0.0050000000000000044\n",
      "mfcc13_var 0.025000000000000022\n",
      "mfcc14_mean -0.0050000000000000044\n",
      "mfcc14_var 0.010000000000000009\n",
      "mfcc15_mean 0.025000000000000022\n",
      "mfcc15_var 0.010000000000000009\n",
      "mfcc16_mean 0.025000000000000022\n",
      "mfcc16_var 0.015000000000000013\n",
      "mfcc17_mean 0.029999999999999916\n",
      "mfcc17_var 0.025000000000000022\n",
      "mfcc18_mean 0.020000000000000018\n",
      "mfcc18_var 0.015000000000000013\n",
      "mfcc19_mean 0.0050000000000000044\n",
      "mfcc19_var 0.010000000000000009\n",
      "mfcc20_mean 0.010000000000000009\n",
      "mfcc20_var 0.020000000000000018\n"
     ]
    }
   ],
   "source": [
    "def feature_ablation(model, test_loader, device):\n",
    "    model.eval()\n",
    "    baseline_acc = get_test_accuracy(model, test_loader, device)  # Get original accuracy\n",
    "    feature_importance = {}\n",
    "\n",
    "    for feature_idx in range(test_loader.dataset[0][0].shape[0]):  # Assuming feature dimension first\n",
    "        y_pred, y_true = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                modified_inputs = inputs.clone()\n",
    "                modified_inputs[:, feature_idx] = 0  # Zero out one feature at a time\n",
    "\n",
    "                outputs = model(modified_inputs)\n",
    "                _, pred = torch.max(outputs, 1)\n",
    "                y_pred.extend(pred.cpu().numpy())\n",
    "                y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        feature_importance[feature_idx] = baseline_acc - acc  # Importance = drop in accuracy\n",
    "\n",
    "    return feature_importance\n",
    "\n",
    "def get_test_accuracy(model, test_loader, device):\n",
    "    y_pred, y_true = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, pred = torch.max(outputs, 1)\n",
    "            y_pred.extend(pred.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "feature_importance = feature_ablation(model, test_loader, device)\n",
    "\n",
    "for idx in range(0, len(feature_importance)):\n",
    "    print(features.columns[idx], feature_importance[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f66b779-dfe0-4ff2-97bb-a21c0c7d29b8",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c504b810-4c13-478f-97b6-55f38e89a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_segment_features(y, sr=22050):\n",
    "    seg_features = []\n",
    "    \n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y=y)\n",
    "    harmony = librosa.effects.harmonic(y=y)\n",
    "    perceptr = librosa.effects.percussive(y=y)\n",
    "    tempo, beats = librosa.beat.beat_track(y=y, sr=sr)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "    \n",
    "    seg_features.append(np.mean(chroma_stft))\n",
    "    seg_features.append(np.var(chroma_stft))\n",
    "    seg_features.append(np.mean(rms))\n",
    "    seg_features.append(np.var(rms))\n",
    "    seg_features.append(np.mean(spectral_centroid))\n",
    "    seg_features.append(np.var(spectral_centroid))\n",
    "    seg_features.append(np.mean(spectral_bandwidth))\n",
    "    seg_features.append(np.var(spectral_bandwidth))\n",
    "    seg_features.append(np.mean(rolloff))\n",
    "    seg_features.append(np.var(rolloff))\n",
    "    seg_features.append(np.mean(zero_crossing_rate))\n",
    "    seg_features.append(np.var(zero_crossing_rate))\n",
    "    seg_features.append(np.mean(harmony))\n",
    "    seg_features.append(np.var(harmony))\n",
    "    seg_features.append(np.mean(perceptr))\n",
    "    seg_features.append(np.var(perceptr))\n",
    "    seg_features.extend(tempo)\n",
    "\n",
    "    for mfcc in mfccs:\n",
    "        seg_features.append(np.mean(mfcc))\n",
    "        seg_features.append(np.var(mfcc))\n",
    "\n",
    "    return seg_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5545a95b-bab6-4f76-a685-b715b895bd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_full_features(filename):\n",
    "    y, sr = librosa.load(filename, sr=22050)\n",
    "\n",
    "    segment_length = 30 * sr\n",
    "    segments = librosa.util.frame(y, frame_length=segment_length, hop_length=segment_length).T\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        full_features = list(executor.map(extract_segment_features, segments))\n",
    "    \n",
    "    return np.mean(full_features, axis=0).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c680058f-81b0-4330-9660-bf024784c60b",
   "metadata": {},
   "source": [
    "## Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "32425c6d-e4be-4c7d-a915-6c0ce997436f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_wav(url):\n",
    "    ydl_opts = {\n",
    "        \"outtmpl\": \"temp_file.%(ext)s\"\n",
    "    }\n",
    "    \n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([url])\n",
    "    \n",
    "    temp_file = \"temp_file.webm\"\n",
    "    wav_file = AudioSegment.from_file(temp_file)\n",
    "    wav_file.export(out_f=\"output_file.wav\", format=\"wav\")\n",
    "    output_file = \"output_file.wav\"\n",
    "    os.remove(temp_file)\n",
    "\n",
    "    return output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4671b4ea-5228-42b7-92e3-d4f870ba1796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Paste URL:  https://www.youtube.com/watch?v=KfEEm4Zx-EU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=KfEEm4Zx-EU\n",
      "[youtube] KfEEm4Zx-EU: Downloading webpage\n",
      "[youtube] KfEEm4Zx-EU: Downloading tv client config\n",
      "[youtube] KfEEm4Zx-EU: Downloading player 56511309\n",
      "[youtube] KfEEm4Zx-EU: Downloading tv player API JSON\n",
      "[youtube] KfEEm4Zx-EU: Downloading ios player API JSON\n",
      "[youtube] KfEEm4Zx-EU: Downloading m3u8 information\n",
      "[info] KfEEm4Zx-EU: Downloading 1 format(s): 399+251\n",
      "[download] Destination: temp_file.f399.mp4\n",
      "[download] 100% of    4.39MiB in 00:00:00 at 5.75MiB/s   \n",
      "[download] Destination: temp_file.f251.webm\n",
      "[download] 100% of    4.11MiB in 00:00:00 at 8.02MiB/s   \n",
      "[Merger] Merging formats into \"temp_file.webm\"\n",
      "Deleting original file temp_file.f251.webm (pass -k to keep)\n",
      "Deleting original file temp_file.f399.mp4 (pass -k to keep)\n",
      "\n",
      "Predicted Genre: Rock\n",
      "\n",
      "Rock: 69.47%\n",
      "Pop: 8.59%\n",
      "Disco: 8.58%\n",
      "Reggae: 8.03%\n",
      "Country: 4.27%\n",
      "Hip-hop: 0.82%\n",
      "Metal: 0.17%\n",
      "Jazz: 0.07%\n",
      "Classical: 0.01%\n",
      "Blues: 0.00%\n"
     ]
    }
   ],
   "source": [
    "url = input(\"Paste URL: \")\n",
    "song_file = convert_to_wav(url)\n",
    "\n",
    "extracted_features = extract_full_features(song_file)\n",
    "features_df = pd.DataFrame(extracted_features, columns=features.columns)\n",
    "scaled_features = scaler.transform(features_df)\n",
    "features_tensor = torch.tensor(scaled_features, dtype=torch.float32).to(device)\n",
    "os.remove(song_file)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(features_tensor)\n",
    "    probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "    \n",
    "    pred_class = torch.argmax(probabilities, dim=1).item()\n",
    "    pred_genre = label_encoder.inverse_transform([pred_class])[0]\n",
    "    print(f\"\\nPredicted Genre: {pred_genre}\\n\")\n",
    "\n",
    "    genre_probabilities = {}\n",
    "    for idx, probability in enumerate(probabilities[0]):\n",
    "        genre = label_encoder.inverse_transform([idx])[0]\n",
    "        genre_probabilities[genre] = probability.item() * 100\n",
    "\n",
    "    sorted_genre_probabilities = sorted(genre_probabilities.items(), key=lambda x: x[1], reverse=True)\n",
    "    for genre, probability in sorted_genre_probabilities:\n",
    "        print(f\"{genre}: {probability:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8afe208-1508-4f07-acec-25011cc7117d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
